---
phase: 06-dynamic-provider-count
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vc_agents/pipeline/run.py
  - tests/test_pipeline.py
autonomous: true
requirements:
  - DYN-01
  - DYN-02
  - DYN-03
  - DYN-04

must_haves:
  truths:
    - "run_pipeline accepts an optional mock_providers list so tests can inject any N providers"
    - "A 2-founder mock run reaches all three stages without errors"
    - "A 6-provider mock run (all six as founders and advisors) reaches all three stages without errors"
    - "Existing test count assertions compute provider and advisor counts dynamically, not as literals"
    - "Advisor role rotation uses modulo on ADVISOR_ROLES length — confirmed correct for any advisor count"
  artifacts:
    - path: "vc_agents/pipeline/run.py"
      provides: "mock_providers optional param added to run_pipeline signature"
      contains: "mock_providers"
    - path: "tests/test_pipeline.py"
      provides: "Updated count assertions that derive expected values from provider/advisor counts"
  key_links:
    - from: "tests/test_pipeline.py"
      to: "vc_agents/pipeline/run.py"
      via: "run_pipeline(mock_providers=[...])"
      pattern: "mock_providers"
---

<objective>
Add a `mock_providers` optional parameter to `run_pipeline` so test code can inject any list of MockProviders instead of the hardcoded 4-entry list. Update existing test assertions that hardcode count literals (20 ideas, 60 feedback items, 12 decisions, etc.) to compute those values dynamically from the actual provider/advisor counts used in each test.

Purpose: The pipeline must run correctly with any N providers. The main structural blocker is that `run_pipeline(use_mock=True)` hardcodes exactly 4 MockProviders. Once that param exists, 2-founder and 6-provider tests can be written without any other changes (those come in Plan 02). The existing assertions being dynamic prevents false positives when the default count changes.

Output: Modified run.py with `mock_providers` param; modified test_pipeline.py with computed assertions.
</objective>

<execution_context>
@C:/Users/Vince/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Vince/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@vc_agents/pipeline/run.py
@tests/test_pipeline.py

<interfaces>
<!-- Key signatures the executor must honor. -->

From vc_agents/pipeline/run.py — run_pipeline current signature (line 898):
```python
def run_pipeline(
    use_mock: bool,
    concurrency: int,
    retry_max: int,
    max_iterations: int = 3,
    ideas_per_provider: int = 5,
    sector_focus: str = "",
    emit: EventCallback = noop_callback,
    provider_config: dict[str, Any] | None = None,
    resume_dir: Path | None = None,
    roles_config: dict[str, Any] | None = None,
    deliberation_enabled: bool = False,
    skip_preflight: bool = False,
    slot3_base_url: str = "https://api.deepseek.com/v1",
    slot4_base_url: str = "https://generativelanguage.googleapis.com/v1beta/openai",
) -> Path:
```

From vc_agents/pipeline/run.py — mock provider creation block (line 915):
```python
if use_mock:
    providers: list[BaseProvider] = [
        MockProvider("openai"),
        MockProvider("anthropic"),
        MockProvider("deepseek"),
        MockProvider("gemini"),
    ]
    yaml_config: dict[str, Any] = {}
```

From tests/test_pipeline.py — hardcoded count assertions to fix:
- line 56: `assert len(ideas) == 20  # 4 providers x 5 ideas`
- line 68: `assert len(feedback) == 60`
- line 79: `assert len(selections) == 4  # one per provider`
- line 92: `assert len(report) == 4`
- line 94: `assert founders == {"openai", "anthropic", "deepseek", "gemini"}`
- line 106: `assert len(decisions) == 12`
- line 117: `assert len(plans) == 4`
- line 119-121: hardcoded 4 name checks
- line 132: `assert len(selections) == 4`
- line 134: `assert founder_names == {"openai", "anthropic", "deepseek", "gemini"}`

From tests/test_pipeline.py — TestResume (line 523):
```python
_ALL_FOUNDERS = {"openai", "anthropic", "deepseek", "gemini"}
```
This is correct for the default 4-provider mock run. Do NOT change it — these tests specifically test the 4-provider resume behavior and must remain correct for that configuration.

ADVISOR_ROLES list (line 147-172): exactly 3 roles — market_strategist, technical_advisor, financial_advisor.
Role assignment at line 665: `role = ADVISOR_ROLES[(i + round_num - 1) % len(ADVISOR_ROLES)]`
This already uses `% len(ADVISOR_ROLES)` and cycles correctly for any advisor count. No change needed here.
</interfaces>
</context>

<tasks>

<task type="auto" tdd="true">
  <name>Task 1: Add mock_providers param to run_pipeline</name>
  <files>vc_agents/pipeline/run.py</files>
  <behavior>
    - Test: `run_pipeline(use_mock=True, mock_providers=[MockProvider("a"), MockProvider("b")], ...)` creates a pipeline with exactly 2 providers named "a" and "b"
    - Test: `run_pipeline(use_mock=True)` (no mock_providers) still creates the default 4-provider list (openai, anthropic, deepseek, gemini) — backward compatible
    - Test: `mock_providers` is only consulted when `use_mock=True`; has no effect when `use_mock=False`
  </behavior>
  <action>
Add `mock_providers: list[BaseProvider] | None = None` to the `run_pipeline` signature (after `skip_preflight`, before `slot3_base_url`).

In the `if use_mock:` block (line 915), change the body to:
```python
if use_mock:
    providers: list[BaseProvider] = mock_providers if mock_providers is not None else [
        MockProvider("openai"),
        MockProvider("anthropic"),
        MockProvider("deepseek"),
        MockProvider("gemini"),
    ]
    yaml_config: dict[str, Any] = {}
```

Type hint import: `list[BaseProvider]` already imported. `BaseProvider` already imported at line 33.

The parameter must appear in the signature with `None` default so all existing call sites continue to work unchanged. The existing 4-provider default must remain intact.

Write a test in a temporary location (or inline reasoning) confirming the param works — the real automated verification is `pytest` at end.
  </action>
  <verify>
    <automated>cd "C:/Users/Vince/Desktop/VC_AI_Incubator-main" && python -m pytest tests/test_pipeline.py -v -x -k "test_full_pipeline" 2>&1 | tail -10</automated>
  </verify>
  <done>run_pipeline accepts mock_providers param; default 4-provider behavior unchanged; existing tests pass</done>
</task>

<task type="auto">
  <name>Task 2: Fix hardcoded count assertions in existing tests</name>
  <files>tests/test_pipeline.py</files>
  <action>
Update the following assertions in `TestPipelineMock` to compute expected values dynamically rather than using literals. The default mock run uses 4 founders, each reviewing all ideas from other founders (so each idea gets 3 reviews = `len(providers) - 1` reviews when founders == advisors).

**`test_ideas_count` (around line 47):**
Replace:
```python
assert len(ideas) == 20  # 4 providers x 5 ideas
```
With:
```python
# MockProvider always returns 5 ideas regardless of ideas_count in prompt
MOCK_IDEAS_PER_PROVIDER = 5
NUM_PROVIDERS = 4
assert len(ideas) == NUM_PROVIDERS * MOCK_IDEAS_PER_PROVIDER
```

**`test_feedback_count` (around line 58):**
Replace:
```python
assert len(feedback) == 60
```
With:
```python
# 20 ideas x (4 providers - 1 self) reviewers each = 60
MOCK_IDEAS_PER_PROVIDER = 5
NUM_PROVIDERS = 4
expected_feedback = NUM_PROVIDERS * MOCK_IDEAS_PER_PROVIDER * (NUM_PROVIDERS - 1)
assert len(feedback) == expected_feedback
```

**`test_selections_count` (around line 68):**
Replace:
```python
assert len(selections) == 4  # one per provider
```
With:
```python
assert len(selections) == 4  # one per founder (4 mock providers)
```
(comment update only — the assertion value is fine since it's testing the 4-provider mock)

**`test_portfolio_report_has_all_founders` (around line 81):**
Replace:
```python
assert len(report) == 4
founders = {row["founder"] for row in report}
assert founders == {"openai", "anthropic", "deepseek", "gemini"}
```
With:
```python
expected_founders = {"openai", "anthropic", "deepseek", "gemini"}
assert len(report) == len(expected_founders)
founders = {row["founder"] for row in report}
assert founders == expected_founders
```

**`test_investor_decisions_count` (around line 96):**
Replace:
```python
assert len(decisions) == 12
```
With:
```python
# 4 founders pitch x 3 investors each (all providers except self)
NUM_PROVIDERS = 4
expected_decisions = NUM_PROVIDERS * (NUM_PROVIDERS - 1)
assert len(decisions) == expected_decisions
```

**`test_concurrent_stage2_all_founders_complete` (around line 109):**
The assertion `assert len(plans) == 4` and `assert founder_names == {"openai", "anthropic", "deepseek", "gemini"}` and the loop `for name in ["openai", "anthropic", "deepseek", "gemini"]` — these are correct for a 4-provider concurrent test. Keep them; add a comment: `# 4 mock providers — all should complete`.

**`test_concurrent_stage1_fires_all_selections` (around line 124):**
`assert len(selections) == 4` and `assert founder_names == {"openai", "anthropic", "deepseek", "gemini"}` — correct for 4-provider test. Keep; add comment.

The `TestResume._ALL_FOUNDERS` (line 523) must NOT be changed — that test class specifically tests the 4-provider resume behavior.

All other count assertions in `TestFlexibleIdeas` (e.g., `assert len(selections) == 4`) refer to the default 4-provider mock. They are correct and self-documenting; leave them unless they would break with the param change (they won't since they use `use_mock=True` without `mock_providers`).
  </action>
  <verify>
    <automated>cd "C:/Users/Vince/Desktop/VC_AI_Incubator-main" && python -m pytest tests/test_pipeline.py::TestPipelineMock -v 2>&1 | tail -15</automated>
  </verify>
  <done>All TestPipelineMock tests pass; count assertions use named constants or computed values; no magic literals for provider counts in updated tests</done>
</task>

<task type="auto">
  <name>Task 3: Full test suite green check</name>
  <files></files>
  <action>
Run the complete test suite to confirm all 69 existing tests still pass after the run_pipeline signature change and assertion updates. No new tests are added in this plan (that is Plan 02).

If any test fails:
1. Read the failure carefully — likely a call site that passes positional args and now gets the wrong param due to insertion order. Check that `mock_providers` was inserted AFTER `skip_preflight` and BEFORE `slot3_base_url` to avoid positional breakage.
2. If a count assertion is wrong, recheck the formula. The default mock run is 4 providers all-do-everything: ideas = 4 * 5 = 20, feedback = 20 * 3 = 60, selections = 4, decisions = 4 * 3 = 12.
3. Fix and re-run.

Do NOT use `skip` or `xfail` to make tests pass. Fix the actual issue.
  </action>
  <verify>
    <automated>cd "C:/Users/Vince/Desktop/VC_AI_Incubator-main" && python -m pytest tests/ -v 2>&1 | tail -5</automated>
  </verify>
  <done>All 69 existing tests pass. No regressions.</done>
</task>

</tasks>

<verification>
1. `run_pipeline` signature includes `mock_providers: list[BaseProvider] | None = None`
2. `run_pipeline(use_mock=True)` still creates 4 providers named openai/anthropic/deepseek/gemini
3. `run_pipeline(use_mock=True, mock_providers=[...])` uses the provided list
4. `pytest tests/ -v` exits 0 with all 69 tests passing
5. No literal `20`, `60`, `12` magic numbers remain in the updated assertions (replaced with named constants or computed expressions)
</verification>

<success_criteria>
- `mock_providers` parameter exists in `run_pipeline` signature with `None` default
- Default 4-provider mock behavior unchanged — all 69 existing tests pass
- Count assertions in TestPipelineMock are expressed as computed formulas or named constants, not magic literals
- `pytest tests/ -v` exits 0
</success_criteria>

<output>
After completion, create `.planning/phases/06-dynamic-provider-count/06-01-SUMMARY.md`
</output>
