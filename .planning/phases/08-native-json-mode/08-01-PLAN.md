---
phase: 08-native-json-mode
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vc_agents/providers/base.py
  - vc_agents/providers/openai_responses.py
  - vc_agents/providers/openai_compatible_chat.py
  - tests/test_pipeline.py
autonomous: true
requirements: [JSON-01, JSON-02, JSON-03, JSON-04]

must_haves:
  truths:
    - "ProviderConfig has a supports_native_json boolean field that defaults to False"
    - "retry_json_call uses a reduced max_retries (1) when provider.config.supports_native_json is True"
    - "OpenAIResponses and OpenAICompatibleChat both set supports_native_json=True and log a confirmation message at DEBUG level"
    - "AnthropicMessages does not set the flag; its effective retry count in retry_json_call is unchanged"
    - "pytest tests/ -v passes with 4 new TestNativeJsonMode tests all green"
  artifacts:
    - path: "vc_agents/providers/base.py"
      provides: "ProviderConfig dataclass with supports_native_json field"
      contains: "supports_native_json"
    - path: "vc_agents/providers/openai_responses.py"
      provides: "OpenAIResponses with flag set True and debug log"
      contains: "supports_native_json"
    - path: "vc_agents/providers/openai_compatible_chat.py"
      provides: "OpenAICompatibleChat with flag set True and debug log"
      contains: "supports_native_json"
    - path: "tests/test_pipeline.py"
      provides: "TestNativeJsonMode covering JSON-01 through JSON-04"
      contains: "TestNativeJsonMode"
  key_links:
    - from: "retry_json_call (run.py)"
      to: "provider.config.supports_native_json"
      via: "conditional: effective_retries = 1 if flag else max_retries"
      pattern: "supports_native_json"
    - from: "OpenAIResponses.__init__"
      to: "ProviderConfig.supports_native_json"
      via: "config field set to True after super().__init__"
      pattern: "self\\.config\\.supports_native_json = True"
---

<objective>
Add a `supports_native_json` boolean flag to `ProviderConfig` so that `retry_json_call` can use a reduced retry count for providers that guarantee well-formed JSON natively (OpenAI Responses API and OpenAI-compatible chat). Non-OpenAI providers retain the full retry count unchanged.

Purpose: OpenAI providers already send `response_format: {type: "json_object"}` / `text.format.type: "json_object"`, making JSON parse failures structurally impossible. Retrying 3 times on a provider that cannot produce malformed JSON wastes time on failures that will never occur. This change makes the retry layer provider-aware.

Output: ProviderConfig with new field, two OpenAI providers flagged and logging, retry_json_call reads the flag, 4 new tests all passing.
</objective>

<execution_context>
@C:/Users/Vince/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Vince/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
</context>

<interfaces>
<!-- Current ProviderConfig in vc_agents/providers/base.py (lines 122-137) -->
```python
@dataclass
class ProviderConfig:
    name: str
    api_key_env: str
    base_url: str
    retry: RetryConfig = field(default_factory=RetryConfig)
    api_key_override: str | None = None

    def require_api_key(self) -> str: ...
```

<!-- Current retry_json_call in vc_agents/pipeline/run.py (lines 297-330) -->
```python
def retry_json_call(
    provider: BaseProvider,
    prompt: str,
    schema: dict[str, Any] | None,
    context: str,
    max_retries: int,
    system: str = "",
) -> dict[str, Any]:
    last_error: Exception | None = None
    for attempt in range(1, max_retries + 1):
        try:
            text = provider.generate(prompt, system=system)
            data = parse_json(text, context)
            if schema is not None:
                data = _normalize_enum_fields(data, schema)
                validate_schema(data, schema, context)
            return data
        except Exception as exc:
            last_error = exc
            logger.warning("%s attempt %d/%d failed: %s", context, attempt, max_retries, exc)
            if attempt == max_retries:
                break
    raise RuntimeError(f"{context} failed after {max_retries} attempts: {last_error}")
```

<!-- OpenAIResponses.__init__ currently builds ProviderConfig then calls super().__init__(config) -->
<!-- OpenAICompatibleChat.__init__ does the same -->
<!-- AnthropicMessages.__init__ does the same — does NOT send response_format -->

<!-- Default retry_max in run_pipeline CLI: int(os.getenv("RETRY_MAX", "3")) -->
<!-- All retry_json_call call sites pass retry_max as the max_retries argument -->
</interfaces>

<tasks>

<task type="auto" tdd="true">
  <name>Task 1: Add supports_native_json to ProviderConfig and update retry_json_call</name>
  <files>vc_agents/providers/base.py, vc_agents/pipeline/run.py</files>
  <behavior>
    - ProviderConfig.supports_native_json defaults to False — existing providers unaffected without code changes
    - retry_json_call: when provider.config.supports_native_json is True, effective_retries = 1 (single attempt; JSON parse errors cannot occur with native mode)
    - retry_json_call: log at DEBUG level "Native JSON mode active for {provider.name} — using 1 attempt" when flag is True and before the loop
    - All existing callers pass max_retries unchanged; the flag override happens inside retry_json_call, not at call sites
    - Non-native providers: behavior identical to today (loop runs max_retries times)
  </behavior>
  <action>
    In vc_agents/providers/base.py, add `supports_native_json: bool = False` as a new field on the `ProviderConfig` dataclass. Place it after `api_key_override` to preserve existing positional argument order for any code that constructs ProviderConfig by position.

    In vc_agents/pipeline/run.py, modify `retry_json_call` to compute the effective retry count at the top of the function body, before the loop:
    ```python
    effective_retries = 1 if provider.config.supports_native_json else max_retries
    if provider.config.supports_native_json:
        logger.debug(
            "Native JSON mode active for %s — using 1 attempt (max_retries=%d ignored)",
            provider.name,
            max_retries,
        )
    ```
    Replace all three occurrences of `max_retries` inside the loop body with `effective_retries`. Do NOT change the function signature or any call sites.
  </action>
  <verify>
    <automated>cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && python -c "from vc_agents.providers.base import ProviderConfig; c = ProviderConfig(name='x', api_key_env='X', base_url='http://x'); assert c.supports_native_json is False; c2 = ProviderConfig(name='y', api_key_env='Y', base_url='http://y', supports_native_json=True); assert c2.supports_native_json is True; print('ProviderConfig OK')"</automated>
  </verify>
  <done>ProviderConfig has the field defaulting to False. retry_json_call uses effective_retries=1 for native providers and logs a debug message. All existing tests still pass (no behavior change for current providers).</done>
</task>

<task type="auto">
  <name>Task 2: Set supports_native_json=True in OpenAI providers</name>
  <files>vc_agents/providers/openai_responses.py, vc_agents/providers/openai_compatible_chat.py</files>
  <action>
    In vc_agents/providers/openai_responses.py, after `super().__init__(config)`, add:
    ```python
    self.config.supports_native_json = True
    logger.debug("OpenAIResponses: native JSON mode active (json_object format enforced)")
    ```
    Import `get_logger` from `vc_agents.logging_config` and create `logger = get_logger("providers.openai_responses")` at module level (or reuse the providers logger if already present — check the existing import pattern in the file; it currently has no logger import, so add it).

    In vc_agents/providers/openai_compatible_chat.py, apply the same pattern after `super().__init__(config)`:
    ```python
    self.config.supports_native_json = True
    logger.debug("OpenAICompatibleChat: native JSON mode active (json_object format enforced)")
    ```
    Add the same logger import. Both files currently import only from `vc_agents.providers.base` — add the logging import alongside it.

    Do NOT touch anthropic_messages.py. The flag stays False there by default.
  </action>
  <verify>
    <automated>cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && python -c "
from vc_agents.providers.openai_responses import OpenAIResponses
from vc_agents.providers.openai_compatible_chat import OpenAICompatibleChat
from vc_agents.providers.anthropic_messages import AnthropicMessages
r = OpenAIResponses.__new__(OpenAIResponses)
r.__init__.__func__ if False else None
p1 = OpenAIResponses(api_key='test')
p2 = OpenAICompatibleChat(api_key='test')
p3 = AnthropicMessages(api_key='test')
assert p1.config.supports_native_json is True, 'OpenAIResponses flag must be True'
assert p2.config.supports_native_json is True, 'OpenAICompatibleChat flag must be True'
assert p3.config.supports_native_json is False, 'AnthropicMessages flag must stay False'
print('Provider flags OK')
"</automated>
  </verify>
  <done>OpenAIResponses.config.supports_native_json is True. OpenAICompatibleChat.config.supports_native_json is True. AnthropicMessages.config.supports_native_json remains False. Both OpenAI providers log a debug message on construction.</done>
</task>

<task type="auto" tdd="true">
  <name>Task 3: Add TestNativeJsonMode tests</name>
  <files>tests/test_pipeline.py</files>
  <behavior>
    - JSON-01: ProviderConfig(name='x', api_key_env='X', base_url='http://x').supports_native_json is False
    - JSON-01: ProviderConfig(..., supports_native_json=True).supports_native_json is True
    - JSON-02: retry_json_call with a native-flagged provider calls provider.generate exactly once even when max_retries=3
    - JSON-03: OpenAIResponses(...).config.supports_native_json is True; OpenAICompatibleChat(...).config.supports_native_json is True; both log at DEBUG
    - JSON-04: AnthropicMessages(...).config.supports_native_json is False; MockProvider(...).config.supports_native_json is False
  </behavior>
  <action>
    Append a new class `TestNativeJsonMode` at the end of tests/test_pipeline.py (after the last existing test class). Import `ProviderConfig` from `vc_agents.providers.base`, `OpenAIResponses` from `vc_agents.providers.openai_responses`, `OpenAICompatibleChat` from `vc_agents.providers.openai_compatible_chat`, `AnthropicMessages` from `vc_agents.providers.anthropic_messages`, and `retry_json_call` from `vc_agents.pipeline.run`.

    ```python
    class TestNativeJsonMode:
        """JSON-01 through JSON-04: supports_native_json flag behavior."""

        def test_json01_provider_config_flag_defaults_false(self):
            """JSON-01: ProviderConfig.supports_native_json defaults to False."""
            config = ProviderConfig(name="x", api_key_env="X", base_url="http://x")
            assert config.supports_native_json is False

        def test_json01_provider_config_flag_can_be_set_true(self):
            """JSON-01: ProviderConfig.supports_native_json can be set to True."""
            config = ProviderConfig(name="x", api_key_env="X", base_url="http://x",
                                    supports_native_json=True)
            assert config.supports_native_json is True

        def test_json02_native_flag_reduces_retries_to_one(self):
            """JSON-02: When supports_native_json=True, retry_json_call calls generate exactly once
            regardless of max_retries value."""
            call_count = 0

            class NativeMock(MockProvider):
                def __init__(self) -> None:
                    super().__init__("native-mock")
                    self.config.supports_native_json = True

                def generate(self, prompt: str, system: str = "") -> str:
                    nonlocal call_count
                    call_count += 1
                    return '{"ideas": []}'

            provider = NativeMock()
            result = retry_json_call(
                provider=provider,
                prompt="dummy",
                schema=None,
                context="test",
                max_retries=3,
            )
            assert call_count == 1, (
                f"Expected exactly 1 call for native JSON provider, got {call_count}"
            )

        def test_json03_openai_providers_have_flag_true(self):
            """JSON-03: OpenAIResponses and OpenAICompatibleChat have supports_native_json=True."""
            r = OpenAIResponses(api_key="test-key")
            c = OpenAICompatibleChat(api_key="test-key")
            assert r.config.supports_native_json is True, "OpenAIResponses must have native JSON flag"
            assert c.config.supports_native_json is True, "OpenAICompatibleChat must have native JSON flag"

        def test_json04_non_openai_providers_have_flag_false(self):
            """JSON-04: AnthropicMessages and MockProvider do NOT have the native JSON flag."""
            a = AnthropicMessages(api_key="test-key")
            m = MockProvider("test-mock")
            assert a.config.supports_native_json is False, "AnthropicMessages must not have native JSON flag"
            assert m.config.supports_native_json is False, "MockProvider must not have native JSON flag"
    ```

    Note: `retry_json_call` is in `vc_agents.pipeline.run`. Add this import to the existing import block at the top of test_pipeline.py:
    ```python
    from vc_agents.providers.base import ProviderConfig
    from vc_agents.providers.openai_responses import OpenAIResponses
    from vc_agents.providers.openai_compatible_chat import OpenAICompatibleChat
    from vc_agents.providers.anthropic_messages import AnthropicMessages
    ```
    `retry_json_call` and `MockProvider` are already imported in test_pipeline.py — verify before adding duplicates.
  </action>
  <verify>
    <automated>cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && pytest tests/test_pipeline.py::TestNativeJsonMode -v</automated>
  </verify>
  <done>5 tests in TestNativeJsonMode all pass. Full suite pytest tests/ -v also passes (no regressions).</done>
</task>

</tasks>

<verification>
Run the full test suite after all tasks complete:

```bash
cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && pytest tests/ -v
```

All tests must pass. Specifically verify:
- TestNativeJsonMode: 5 tests, all green
- All prior test classes: no regressions
- No import errors from the new logger additions in openai_responses.py and openai_compatible_chat.py
</verification>

<success_criteria>
1. `ProviderConfig` has `supports_native_json: bool = False` — existing code constructing ProviderConfig without the field continues to work unchanged (JSON-01)
2. `retry_json_call` uses `effective_retries = 1` when `provider.config.supports_native_json is True`, logs a DEBUG message, and still uses `max_retries` for all other providers (JSON-02, JSON-04)
3. `OpenAIResponses` and `OpenAICompatibleChat` both set `self.config.supports_native_json = True` and emit a DEBUG log on construction (JSON-03)
4. `AnthropicMessages`, `MockProvider`, and any future provider that does not explicitly set the flag will use the full retry count (JSON-04)
5. `pytest tests/ -v` passes with 5 new TestNativeJsonMode tests and zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/08-native-json-mode/08-01-SUMMARY.md` using the summary template at `@C:/Users/Vince/.claude/get-shit-done/templates/summary.md`.
</output>
