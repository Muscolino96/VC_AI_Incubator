---
phase: 09-live-cost-tracking
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vc_agents/pipeline/cost_tracker.py
  - vc_agents/pipeline/run.py
  - vc_agents/web/server.py
autonomous: true
requirements: [COST-01, COST-02, COST-04, COST-05]

must_haves:
  truths:
    - "After each API call, cost is computed from actual token delta × model pricing from models_catalog.yaml"
    - "run_pipeline maintains a running_cost float and includes it in every step_complete event payload"
    - "--budget N stops the pipeline gracefully after the step that causes the total to exceed N, saves checkpoint, prints message"
    - "cost_report.json is written to the run_dir alongside token_usage.json on both normal completion and budget-stop"
    - "server.py accepts budget from RunConfig and passes it to run_pipeline"
  artifacts:
    - path: "vc_agents/pipeline/cost_tracker.py"
      provides: "CostTracker class: pricing lookup from models_catalog.yaml, per-call cost calculation, running total, BudgetExceeded exception"
      exports: ["CostTracker", "BudgetExceeded"]
    - path: "vc_agents/pipeline/run.py"
      provides: "run_pipeline with budget param, cost tracking after each step, cost_report.json write, --budget CLI flag"
      contains: "budget: float | None = None"
    - path: "vc_agents/web/server.py"
      provides: "RunConfig.budget field forwarded to run_pipeline"
      contains: "budget"
  key_links:
    - from: "vc_agents/pipeline/run.py"
      to: "vc_agents/pipeline/cost_tracker.py"
      via: "CostTracker instantiated in run_pipeline, passed into stage functions or checked after each emit"
      pattern: "CostTracker"
    - from: "vc_agents/pipeline/run.py"
      to: "models_catalog.yaml"
      via: "CostTracker reads catalog at construction time"
      pattern: "load_catalog|CostTracker"
    - from: "vc_agents/pipeline/run.py"
      to: "run_dir/cost_report.json"
      via: "written in same finally-adjacent block as token_usage.json"
      pattern: "cost_report"
---

<objective>
Add per-call cost calculation, running total tracking, budget enforcement, and cost_report.json output to the pipeline backend.

Purpose: Give operators full cost visibility and control: they can cap spend with `--budget` and get a breakdown file after every run.
Output: `vc_agents/pipeline/cost_tracker.py`, updated `run.py` and `server.py`.
</objective>

<execution_context>
@C:/Users/Vince/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Vince/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@vc_agents/pipeline/run.py
@vc_agents/providers/base.py
@vc_agents/pipeline/cost_estimator.py
@vc_agents/web/server.py
@models_catalog.yaml
</context>

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From vc_agents/providers/base.py:
```python
@dataclass
class TokenUsage:
    input_tokens: int = 0
    output_tokens: int = 0

    @property
    def total(self) -> int: ...

    def add(self, input_tokens: int, output_tokens: int) -> None: ...

class BaseProvider:
    usage: TokenUsage
    config: ProviderConfig  # config.name = provider name, no .model on config
    # Each concrete provider has: self.model: str (set in __init__)
```

From vc_agents/pipeline/cost_estimator.py (shows how catalog is loaded):
```python
from pathlib import Path
import yaml

CATALOG_PATH = Path(__file__).resolve().parents[2] / "models_catalog.yaml"

def load_catalog() -> dict[str, Any]:
    with CATALOG_PATH.open(encoding="utf-8") as f:
        return yaml.safe_load(f) or {}

# models_catalog.yaml structure:
# catalog:
#   - id: gpt-5.2
#     pricing: { input: 1.75, output: 14.00 }   # USD per 1M tokens
#   - id: claude-opus-4-6
#     pricing: { input: 5.00, output: 25.00 }
```

From vc_agents/pipeline/run.py (run_pipeline signature):
```python
def run_pipeline(
    use_mock: bool,
    concurrency: int,
    retry_max: int,
    max_iterations: int = 3,
    ideas_per_provider: int = 5,
    sector_focus: str = "",
    emit: EventCallback = noop_callback,
    provider_config: dict[str, Any] | None = None,
    resume_dir: Path | None = None,
    roles_config: dict[str, Any] | None = None,
    deliberation_enabled: bool = False,
    skip_preflight: bool = False,
    mock_providers: list[BaseProvider] | None = None,
    slot3_base_url: str = "...",
    slot4_base_url: str = "...",
) -> Path: ...
```

From vc_agents/pipeline/run.py (existing token_usage write, lines 1110-1125):
```python
# Log and save token usage
token_summary: dict[str, Any] = {}
for provider in providers:
    token_summary[provider.name] = {
        "input_tokens": provider.usage.input_tokens,
        "output_tokens": provider.usage.output_tokens,
        "total_tokens": provider.usage.total,
    }
token_usage_path = run_dir / "token_usage.json"
token_usage_path.write_text(json.dumps(token_summary, indent=2), encoding="utf-8")
```

From vc_agents/pipeline/run.py (emit call pattern):
```python
emit(PipelineEvent(
    type=EventType.STEP_COMPLETE, stage="stage1", step="ideas",
    provider=provider.name, message="...",
    data={"ideas": idea_items},
))
```

From vc_agents/pipeline/events.py (PipelineEvent accepts arbitrary data dict):
```python
@dataclass
class PipelineEvent:
    type: EventType
    stage: str = ""
    step: str = ""
    provider: str = ""
    idea_id: str = ""
    message: str = ""
    data: dict[str, Any] = field(default_factory=dict)
```

From vc_agents/web/server.py (RunConfig):
```python
class RunConfig(BaseModel):
    use_mock: bool = True
    concurrency: int = 1
    retry_max: int = 3
    max_iterations: int = 3
    ideas_per_provider: int = 5
    # ... other fields, add budget: float | None = None
```

From vc_agents/web/server.py (_run_in_thread calls run_pipeline at line 135):
```python
run_dir = run_pipeline(
    use_mock=config.get("use_mock", True),
    concurrency=config.get("concurrency", 1),
    retry_max=config.get("retry_max", 3),
    max_iterations=config.get("max_iterations", 3),
    ideas_per_provider=config.get("ideas_per_provider", 5),
    sector_focus=sector,
    deliberation_enabled=config.get("deliberation_enabled", False),
    emit=emit,
    provider_config=config,
    slot3_base_url=slot3_base_url,
    slot4_base_url=slot4_base_url,
)
```
</interfaces>

<tasks>

<task type="auto" tdd="true">
  <name>Task 1: Create CostTracker with pricing lookup and BudgetExceeded exception</name>
  <files>vc_agents/pipeline/cost_tracker.py</files>
  <behavior>
    - CostTracker(providers, budget=None) loads models_catalog.yaml at construction, builds {model_id: {input, output}} pricing dict
    - record_step(providers) snapshots current usage, computes delta since last snapshot, sums cost across all providers, updates running_cost
    - calculate_cost(model_id, input_delta, output_delta) -> float: looks up pricing, computes (input_delta/1e6)*input_price + (output_delta/1e6)*output_price; returns 0.0 if model not in catalog (with debug log)
    - running_cost property returns accumulated float
    - check_budget() raises BudgetExceeded(running_cost, budget) if running_cost > budget and budget is not None
    - cost_report() -> dict: returns {"total_cost_usd": X, "providers": {name: {"input_tokens": N, "output_tokens": N, "cost_usd": X}}, "budget_usd": budget_or_null}
    - BudgetExceeded is a RuntimeError subclass with .running_cost and .budget attributes
    - Provider model is accessed via provider.model (attribute set on each concrete provider, not on ProviderConfig)
  </behavior>
  <action>
    Create `vc_agents/pipeline/cost_tracker.py`:

    1. Import: Path, yaml, dataclass, Any, logger from vc_agents.logging_config
    2. CATALOG_PATH = Path(__file__).resolve().parents[2] / "models_catalog.yaml"
    3. class BudgetExceeded(RuntimeError): has .running_cost (float) and .budget (float) set in __init__
    4. class CostTracker:
       - __init__(self, providers: list, budget: float | None = None):
         - Load catalog, build self._pricing: dict[str, dict] = {model_id: {"input": float, "output": float}}
         - self._providers = providers
         - self._budget = budget
         - self._running_cost: float = 0.0
         - self._last_usage: dict[str, tuple[int, int]] = {p.name: (p.usage.input_tokens, p.usage.output_tokens) for p in providers}
         - self._per_provider_cost: dict[str, float] = {p.name: 0.0 for p in providers}
       - record_step(self) -> float (returns cost increment this step):
         - For each provider: compute input_delta = current - last, output_delta = current - last
         - Get model_id via getattr(provider, 'model', '') — concrete providers all have self.model
         - Call _calculate_cost(model_id, input_delta, output_delta) → step_cost
         - Accumulate into self._per_provider_cost[provider.name]
         - Update self._last_usage
         - Add to self._running_cost
         - Return total increment
       - _calculate_cost(self, model_id: str, input_delta: int, output_delta: int) -> float:
         - Look up self._pricing.get(model_id); if missing, logger.debug("model %s not in catalog, cost=0", model_id)
         - Return (input_delta / 1_000_000) * p["input"] + (output_delta / 1_000_000) * p["output"]
       - @property running_cost(self) -> float: return self._running_cost
       - check_budget(self) -> None: if self._budget and self._running_cost > self._budget: raise BudgetExceeded(self._running_cost, self._budget)
       - cost_report(self) -> dict: return structured report dict
    5. Add type hints on all methods. No magic numbers (price divisor = 1_000_000 as a named constant or inline comment).
  </action>
  <verify>
    <automated>cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && python -m pytest tests/test_cost_tracker.py -x -q 2>&1 | head -30</automated>
  </verify>
  <done>CostTracker calculates cost correctly from token deltas, raises BudgetExceeded when threshold exceeded, returns correct cost_report dict. Tests pass.</done>
</task>

<task type="auto" tdd="true">
  <name>Task 2: Integrate CostTracker into run_pipeline — running total in events, budget enforcement, cost_report.json, CLI flag</name>
  <files>vc_agents/pipeline/run.py, vc_agents/web/server.py</files>
  <behavior>
    - run_pipeline accepts budget: float | None = None (new param after skip_preflight)
    - After each stage function returns (run_stage1, run_stage2, run_stage3), call tracker.record_step() then tracker.check_budget()
    - step_complete events gain running_cost key in their data dict: data={"...existing...", "running_cost": tracker.running_cost}
    - Since stage functions emit their own events internally, the budget check happens at stage boundaries (after each stage function call), NOT inside stage functions. This is the simplest correct approach for this pipeline.
    - BudgetExceeded is caught in run_pipeline's try/except block: save checkpoint, write cost_report.json, emit pipeline_error, re-raise as RuntimeError with "Budget exceeded: spent $X.XX of $Y.YY limit" message
    - cost_report.json is written in BOTH success path (alongside token_usage.json) AND in the BudgetExceeded handler before re-raise
    - token_usage.json existing write gains estimated_cost_usd per provider from tracker._per_provider_cost
    - parse_args adds --budget argument: type=float, default=None, help="Stop pipeline if running cost exceeds this amount (USD)"
    - main() passes args.budget to run_pipeline
    - server.py: RunConfig gains budget: float | None = None field; _run_in_thread passes config.get("budget") to run_pipeline
  </behavior>
  <action>
    **In vc_agents/pipeline/run.py:**

    1. Add import: `from vc_agents.pipeline.cost_tracker import CostTracker, BudgetExceeded`

    2. Add `budget: float | None = None` parameter to `run_pipeline()` after `slot4_base_url`. Keep all existing params in existing order.

    3. After providers are constructed and before the try block, instantiate tracker:
       ```python
       tracker = CostTracker(providers, budget=budget)
       ```

    4. In run_pipeline's try block, wrap each stage call. After each stage function call, update the running cost and check budget. Pattern for each:
       ```python
       # After run_stage1() call:
       tracker.record_step()
       tracker.check_budget()

       # After run_stage2() call (the partial/remaining path):
       tracker.record_step()
       tracker.check_budget()

       # After run_stage3() call:
       tracker.record_step()
       tracker.check_budget()
       ```

    5. Extend the existing `except (ProviderError, RuntimeError) as exc:` block to also handle BudgetExceeded FIRST (before the broad RuntimeError):
       ```python
       except BudgetExceeded as exc:
           logger.warning(
               "Budget exceeded: spent $%.4f of $%.4f limit — stopping after current step",
               exc.running_cost, exc.budget,
           )
           existing_cp = _load_checkpoint(run_dir) or {}
           _save_checkpoint(run_dir, existing_cp)
           _write_cost_report(run_dir, tracker, providers)
           emit(PipelineEvent(
               type=EventType.PIPELINE_ERROR,
               message=f"Budget exceeded: spent ${exc.running_cost:.4f} of ${exc.budget:.4f} limit",
           ))
           raise RuntimeError(
               f"Budget exceeded: spent ${exc.running_cost:.4f} of ${exc.budget:.4f} limit"
           ) from exc
       ```
       Keep existing `except (ProviderError, RuntimeError)` block after this.

    6. Extract a helper `_write_cost_report(run_dir: Path, tracker: CostTracker, providers: list[BaseProvider]) -> None` that writes `run_dir / "cost_report.json"` using `tracker.cost_report()`. Call it in both the success path (alongside token_usage.json write) and the BudgetExceeded handler.

    7. In the token_usage success block, enhance token_summary to include cost per provider:
       ```python
       token_summary[provider.name] = {
           "input_tokens": provider.usage.input_tokens,
           "output_tokens": provider.usage.output_tokens,
           "total_tokens": provider.usage.total,
           "estimated_cost_usd": round(tracker._per_provider_cost.get(provider.name, 0.0), 6),
       }
       ```

    8. In `parse_args()`, add:
       ```python
       parser.add_argument(
           "--budget", type=float, default=None,
           help="Stop pipeline gracefully if running cost exceeds this amount in USD (e.g. --budget 0.50)",
       )
       ```

    9. In `main()`, pass `budget=args.budget` to `run_pipeline(...)`.

    **NOTE on step events:** The stage functions emit their own step_complete events internally. To include running_cost in those events, the cleanest approach is to emit a single `step_complete` event with running_cost AFTER each stage in run_pipeline rather than threading tracker into each stage function. Add this after each stage's tracker.record_step() call:
    ```python
    emit(PipelineEvent(
        type=EventType.STEP_COMPLETE, stage="stage1", step="cost_update",
        message=f"Running cost: ${tracker.running_cost:.4f}",
        data={"running_cost": tracker.running_cost},
    ))
    ```
    Do this after stage1, stage2, and stage3 tracker.record_step() calls.

    **In vc_agents/web/server.py:**

    1. Add `budget: float | None = None` to RunConfig Pydantic model.

    2. In `_run_in_thread`, add `budget=config.get("budget")` to the `run_pipeline(...)` call.
  </action>
  <verify>
    <automated>cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && python -m pytest tests/test_pipeline.py tests/test_cost_tracker.py -x -q 2>&1 | tail -20</automated>
  </verify>
  <done>
    - run_pipeline(budget=0.001, use_mock=True) raises RuntimeError containing "Budget exceeded" message
    - run_pipeline(use_mock=True) writes cost_report.json in run_dir
    - cost_report.json contains total_cost_usd and per-provider breakdown
    - token_usage.json includes estimated_cost_usd per provider
    - All existing tests pass (mock providers have usage.input_tokens=0 so cost=0, budget never triggered unless budget=0)
    - pytest tests/test_pipeline.py tests/test_cost_tracker.py -x passes
  </done>
</task>

</tasks>

<verification>
- `python -m pytest tests/ -v` — all 80+ existing tests pass
- `python -m vc_agents.pipeline.run --help` shows `--budget` argument
- Mock run produces cost_report.json: `python -c "from pathlib import Path; import json; import tempfile, os; os.chdir(tempfile.mkdtemp()); from vc_agents.pipeline.run import run_pipeline; d = run_pipeline(use_mock=True, concurrency=1, retry_max=1, max_iterations=1); print(json.loads((d / 'cost_report.json').read_text()))"`
- Budget stop: `python -c "from vc_agents.pipeline.run import run_pipeline; import tempfile, os; os.chdir(tempfile.mkdtemp()); run_pipeline(use_mock=True, concurrency=1, retry_max=1, max_iterations=1, budget=0.0)"` raises RuntimeError with "Budget exceeded"
</verification>

<success_criteria>
- CostTracker reads models_catalog.yaml pricing, computes cost from token deltas, tracks running total
- BudgetExceeded raised when running_cost > budget; pipeline saves checkpoint and writes cost_report.json before stopping
- cost_report.json written on both normal completion and budget-stop
- run_pipeline emits cost_update step events with running_cost
- server.py RunConfig has budget field, passes to run_pipeline
- All existing pytest tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/09-live-cost-tracking/09-01-SUMMARY.md`
</output>
