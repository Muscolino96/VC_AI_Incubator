---
phase: 03-resume-fix
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vc_agents/pipeline/run.py
  - tests/test_pipeline.py
autonomous: true
requirements:
  - RES-01
  - RES-02
  - RES-03
  - RES-04

must_haves:
  truths:
    - "After each founder finishes Stage 2, their name appears in checkpoint.json under stage2_founders_done"
    - "On resume with two founders already done, zero API calls are made for those two founders"
    - "Resumed run loads each done founder's plan from the highest-versioned plan file on disk"
    - "Loaded plan data structure is identical to a freshly generated plan (same keys, same founder_provider)"
    - "pytest tests/ -v passes including new resume tests"
  artifacts:
    - path: "vc_agents/pipeline/run.py"
      provides: "Per-founder checkpoint write in run_stage2 merge loop; per-founder resume read in run_pipeline"
      contains: "stage2_founders_done"
    - path: "tests/test_pipeline.py"
      provides: "TestResume class with mid-Stage-2 crash simulation test"
      contains: "TestResume"
  key_links:
    - from: "run_stage2 merge loop"
      to: "checkpoint.json"
      via: "_save_checkpoint with stage2_founders_done list updated per founder"
      pattern: "stage2_founders_done"
    - from: "run_pipeline Stage 2 block"
      to: "stage2_{founder}_plan_v*.jsonl"
      via: "_load_founder_plan_from_disk selecting highest version by glob sort"
      pattern: "_load_founder_plan_from_disk"
---

<objective>
Fix Stage 2 resume so a crash mid-Stage-2 resumes from the last completed founder rather than restarting all of Stage 2 from scratch.

Purpose: Prevents re-spending $2-5 per completed founder when a crash occurs. Each founder takes 6-15 minutes of real API calls.
Output: Modified run.py with per-founder checkpoint writes and resume reads; new TestResume tests in test_pipeline.py.
</objective>

<execution_context>
@C:/Users/Vince/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Vince/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@vc_agents/pipeline/run.py
@tests/test_pipeline.py

<interfaces>
<!-- Key contracts the executor needs. No codebase exploration required. -->

From vc_agents/pipeline/run.py — relevant functions:

```python
def _save_checkpoint(run_dir: Path, data: dict[str, Any]) -> None:
    """Save pipeline checkpoint to disk."""
    checkpoint_path = run_dir / "checkpoint.json"
    checkpoint_path.write_text(json.dumps(data, indent=2), encoding="utf-8")

def _load_checkpoint(run_dir: Path) -> dict[str, Any] | None:
    """Load pipeline checkpoint from disk if it exists."""
    checkpoint_path = run_dir / "checkpoint.json"
    if checkpoint_path.exists():
        return json.loads(checkpoint_path.read_text(encoding="utf-8"))
    return None

def _load_jsonl(path: Path) -> list[dict[str, Any]]:
    """Load records from a JSONL file."""
    ...

def _write_jsonl(path: Path, records: list[dict[str, Any]]) -> None:
    ...
```

Stage 2 call site in run_pipeline (lines ~939-949):
```python
# Stage 2: Build and Iterate
if checkpoint and checkpoint.get("stage2_complete"):
    logger.info("Resuming: loading Stage 2 plans from checkpoint")
    plans_list = _load_jsonl(run_dir / "stage2_final_plans.jsonl")
    final_plans = {p["founder_provider"]: p for p in plans_list}
else:
    final_plans = run_stage2(
        providers, selections, retry_max, concurrency, max_iterations, run_dir,
        emit=emit, roles=roles, deliberation_enabled=effective_deliberation,
    )
    _save_checkpoint(run_dir, {"stage1_complete": True, "stage2_complete": True})
```

Stage 2 merge loop in run_stage2 (lines ~710-719):
```python
final_plans: dict[str, dict[str, Any]] = {}
all_reviews: list[dict[str, Any]] = []
for f_name, f_plan, f_reviews in _map_concurrently(
    _run_founder_stage2, founders_list, concurrency
):
    final_plans[f_name] = f_plan
    all_reviews.extend(f_reviews)

_write_jsonl(run_dir / "stage2_final_plans.jsonl", list(final_plans.values()))
_write_jsonl(run_dir / "stage2_all_reviews.jsonl", all_reviews)
```

run_stage2 signature:
```python
def run_stage2(
    providers: list[BaseProvider],
    selections: dict[str, dict[str, Any]],
    retry_max: int,
    concurrency: int,
    max_iterations: int,
    run_dir: Path,
    emit: EventCallback = noop_callback,
    roles: RoleAssignment | None = None,
    deliberation_enabled: bool = False,
) -> dict[str, dict[str, Any]]:
```

_run_founder_stage2 inner function signature and return:
```python
def _run_founder_stage2(
    founder: BaseProvider,
) -> tuple[str, dict[str, Any], list[dict[str, Any]]]:
    """Run one founder's full Stage 2 cycle. Returns (name, final_plan, reviews)."""
    ...
    return founder.name, plan, founder_reviews
```

Checkpoint format after Stage 1:
```json
{"stage1_complete": true}
```

Target checkpoint format after each founder finishes Stage 2:
```json
{"stage1_complete": true, "stage2_founders_done": ["openai", "anthropic"]}
```

Per-founder plan files written to disk during Stage 2 (already happens today):
  stage2_{founder.name}_plan_v0.jsonl   — initial build
  stage2_{founder.name}_plan_v1.jsonl   — after round 1
  stage2_{founder.name}_plan_v2.jsonl   — after round 2
  (highest version number = final plan)

MockProvider import in tests:
```python
from vc_agents.providers.mock import MockProvider
```
</interfaces>
</context>

<tasks>

<task type="auto" tdd="true">
  <name>Task 1: Add _load_founder_plan_from_disk helper and per-founder checkpoint write</name>
  <files>vc_agents/pipeline/run.py</files>
  <behavior>
    - _load_founder_plan_from_disk("openai", run_dir) when plan_v2.jsonl exists returns the record from that file
    - _load_founder_plan_from_disk("openai", run_dir) when plan_v0.jsonl and plan_v1.jsonl both exist returns record from plan_v1.jsonl (highest)
    - _load_founder_plan_from_disk("openai", run_dir) when no plan files exist raises FileNotFoundError
    - After the _map_concurrently merge loop collects one founder's result, checkpoint.json is updated with that founder added to stage2_founders_done
  </behavior>
  <action>
Add a module-level helper function `_load_founder_plan_from_disk(founder_name: str, run_dir: Path) -> dict[str, Any]` after the existing `_load_jsonl` function (around line 348). It must:
  1. Glob `run_dir / f"stage2_{founder_name}_plan_v*.jsonl"` to find all versioned plan files for this founder
  2. Sort by version number (extract the integer after `_plan_v` and before `.jsonl`) to find the highest version
  3. Return `_load_jsonl(highest_version_file)[0]` — the first (and only) record in that file
  4. Raise `FileNotFoundError(f"No Stage 2 plan files found for {founder_name} in {run_dir}")` if no files match

Then modify the merge loop in `run_stage2` (the `for f_name, f_plan, f_reviews in _map_concurrently(...)` block, lines ~712-716) to write a per-founder checkpoint after each result is collected:
  - After `final_plans[f_name] = f_plan` and `all_reviews.extend(f_reviews)`, call:
    `_save_checkpoint(run_dir, {**(_load_checkpoint(run_dir) or {}), "stage2_founders_done": list(final_plans.keys())})`
  - This merges with the existing checkpoint (preserving `stage1_complete: true`) and sets `stage2_founders_done` to the list of all founders collected so far
  - Because `_map_concurrently` yields results serially into the merge loop (even though work runs concurrently), this per-founder checkpoint write is safe without a lock
  </action>
  <verify>
    <automated>cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && python -m pytest tests/test_pipeline.py -v -k "resume" -x 2>&1 | tail -20</automated>
  </verify>
  <done>
    - `_load_founder_plan_from_disk` exists and selects the highest-versioned plan file by integer sort
    - After each founder result is merged in run_stage2, checkpoint.json contains `stage2_founders_done` with that founder's name
    - All existing tests still pass: `pytest tests/ -v` green
  </done>
</task>

<task type="auto" tdd="true">
  <name>Task 2: Per-founder resume read path in run_pipeline Stage 2 block</name>
  <files>vc_agents/pipeline/run.py</files>
  <behavior>
    - When checkpoint has stage2_founders_done: ["openai", "anthropic"] and 4 founders are configured, run_stage2 is called with only ["deepseek", "gemini"]
    - Plans for skipped founders are loaded via _load_founder_plan_from_disk, not via API calls
    - The merged final_plans dict has all 4 founders regardless of how many were skipped
    - When all founders are already done (stage2_founders_done has all 4), run_stage2 is not called at all
    - When no founders are done and stage1_complete is true, existing behavior (full run_stage2) is unchanged
  </behavior>
  <action>
Replace the Stage 2 block in `run_pipeline` (lines ~939-949). The new logic:

```python
# Stage 2: Build and Iterate
if checkpoint and checkpoint.get("stage2_complete"):
    logger.info("Resuming: loading Stage 2 plans from checkpoint")
    plans_list = _load_jsonl(run_dir / "stage2_final_plans.jsonl")
    final_plans = {p["founder_provider"]: p for p in plans_list}
else:
    founders_done: list[str] = (checkpoint or {}).get("stage2_founders_done", [])
    founders_list = roles.founders if roles is not None else providers

    # Load plans for already-completed founders
    final_plans: dict[str, dict[str, Any]] = {}
    for founder in founders_list:
        if founder.name in founders_done:
            logger.info("Resuming: skipping %s (already in stage2_founders_done)", founder.name)
            final_plans[founder.name] = _load_founder_plan_from_disk(founder.name, run_dir)

    # Run Stage 2 for any remaining founders
    remaining = [f for f in founders_list if f.name not in founders_done]
    if remaining:
        partial = run_stage2(
            remaining, selections, retry_max, concurrency, max_iterations, run_dir,
            emit=emit, roles=roles, deliberation_enabled=effective_deliberation,
        )
        final_plans.update(partial)
    else:
        logger.info("Resuming: all founders already done, skipping Stage 2")
        emit(PipelineEvent(type=EventType.STAGE_START, stage="stage2", message="Build and Iterate"))
        emit(PipelineEvent(type=EventType.STAGE_COMPLETE, stage="stage2", message="Build and Iterate complete"))

    _save_checkpoint(run_dir, {"stage1_complete": True, "stage2_complete": True})
```

Key implementation notes:
- `founders_list` must be derived from `roles.founders` (same as run_stage2 does internally) to respect role assignments
- The `remaining` list passed to `run_stage2` is a subset of providers — run_stage2 already accepts any list of providers as `providers` parameter; the `founders_list` override in run_stage2 uses `roles.founders if roles is not None else providers`, so pass `roles=None` is wrong — pass `roles=roles` as before; run_stage2 will internally use `roles.founders` which is the full list, then filter. WAIT: this is a problem — run_stage2 ignores the `providers` arg and uses `roles.founders`. Fix: pass `remaining` as the providers arg AND pass `roles=None` so run_stage2 uses the `providers` arg (the `remaining` list) as the founders_list. But advisors should still come from `roles.advisors`. To avoid breaking the roles system, instead pass `roles` with a modified founders list. The cleanest approach: pass `roles=None` for the remaining-only call, but then the advisor pool falls back to `providers` (the `remaining` list only), losing the other advisors. Better approach: add a `founders_override` parameter to run_stage2, OR simply pass `roles` as-is and add a `founders_filter` param. Actually simplest: construct a modified roles object. Look at the existing code:

```python
founders_list = roles.founders if roles is not None else providers
```

The cleanest fix that doesn't change run_stage2 signature: pass the full `roles` object but add a keyword argument `founders_override: list[BaseProvider] | None = None` to `run_stage2`. When set, use it instead of `roles.founders`. Set it to `remaining` when calling for partial resume.

Alternatively — simpler with no signature change: in the resume path, temporarily set `roles.founders = remaining` before calling run_stage2, restore it after. But RoleAssignment is a dataclass so fields are mutable.

Simplest correct approach: Add `founders_override: list[BaseProvider] | None = None` parameter to `run_stage2`. Inside run_stage2, change:
```python
founders_list = roles.founders if roles is not None else providers
```
to:
```python
if founders_override is not None:
    founders_list = founders_override
elif roles is not None:
    founders_list = roles.founders
else:
    founders_list = providers
```

Then call: `run_stage2(..., roles=roles, founders_override=remaining, ...)` in the resume path.
  </action>
  <verify>
    <automated>cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && python -m pytest tests/test_pipeline.py -v -k "resume" -x 2>&1 | tail -30</automated>
  </verify>
  <done>
    - Resuming with 2 founders in stage2_founders_done calls run_stage2 with only the 2 remaining founders
    - Skipped founders' plans are loaded from disk via _load_founder_plan_from_disk
    - final_plans contains all 4 founders after the merge
    - All existing pytest tests pass
  </done>
</task>

<task type="auto">
  <name>Task 3: Write TestResume tests for mid-Stage-2 crash and correct resume</name>
  <files>tests/test_pipeline.py</files>
  <action>
Add a `TestResume` class to `tests/test_pipeline.py` after the existing `TestPipelineMock` class. Add the following tests:

**test_founder_checkpoint_written_after_each_founder:**
Run a full mock pipeline. After completion, read `checkpoint.json`. Assert that `stage2_founders_done` exists and contains exactly the 4 founder names (as a set: `{"openai", "anthropic", "deepseek", "gemini"}`).

**test_resume_skips_completed_founders_no_extra_calls:**
Simulate a mid-Stage-2 crash with 2 founders done:
1. Run full pipeline with `use_mock=True` to get a valid `run_dir` with all files on disk.
2. Patch `checkpoint.json` to set `stage2_founders_done: ["openai", "anthropic"]` and remove `stage2_complete` (so resume enters the partial path).
3. Count how many times `MockProvider.generate` is called during a `run_pipeline(resume_dir=run_dir, use_mock=True, ...)`.
4. Assert that `openai` and `anthropic`'s providers are never called during the resumed run.
   Implementation: Use `monkeypatch` to wrap `MockProvider.generate` with a counter that records which provider name called it. Assert neither `"openai"` nor `"anthropic"` appear in the call log.

**test_resume_loads_plan_from_disk_with_correct_structure:**
1. Run full pipeline to get a `run_dir` with valid plan files.
2. Read `stage2_openai_plan_v0.jsonl` to get the plan record.
3. Patch `checkpoint.json`: set `stage2_founders_done: ["openai"]`, remove `stage2_complete`.
4. Call `_load_founder_plan_from_disk("openai", run_dir)` directly.
5. Assert the returned dict has key `"founder_provider"` equal to `"openai"`.
6. Assert it has the same keys as a plan produced by a fresh run (check `"idea_id"`, `"founder_provider"` at minimum).

**test_resume_selects_highest_version_plan:**
1. In `tmp_path`, create two fake plan files: `stage2_openai_plan_v0.jsonl` (with `{"founder_provider": "openai", "version": 0}`) and `stage2_openai_plan_v1.jsonl` (with `{"founder_provider": "openai", "version": 1}`).
2. Call `_load_founder_plan_from_disk("openai", tmp_path)`.
3. Assert the returned dict has `"version": 1` (highest wins).

Import `_load_founder_plan_from_disk` from `vc_agents.pipeline.run` at the top of the test class.
  </action>
  <verify>
    <automated>cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && python -m pytest tests/test_pipeline.py::TestResume -v 2>&1 | tail -20</automated>
  </verify>
  <done>
    - All 4 TestResume tests pass
    - Full test suite passes: `pytest tests/ -v` exits 0
    - RES-01: checkpoint written with stage2_founders_done after each founder (test 1)
    - RES-02: skipped founders make zero API calls (test 2)
    - RES-03: skipped founders' plans loaded from highest-versioned file (tests 3, 4)
    - RES-04: loaded plan has same structure as freshly generated plan (test 3)
  </done>
</task>

</tasks>

<verification>
Full test suite must pass:
```
cd C:/Users/Vince/Desktop/VC_AI_Incubator-main && python -m pytest tests/ -v
```

Checkpoint format check (manual):
Run `python -m vc_agents.pipeline.run --mock --max-iterations 1 --ideas-per-provider 2` and inspect `out/run_*/checkpoint.json` — should contain `stage2_founders_done` with all 4 founder names.
</verification>

<success_criteria>
1. checkpoint.json contains `stage2_founders_done: ["openai", "anthropic", "deepseek", "gemini"]` after a completed run
2. Resuming with N founders in `stage2_founders_done` makes zero API calls for those N founders
3. Loaded plans pass the same schema as fresh plans (same keys: `founder_provider`, `idea_id`, etc.)
4. `pytest tests/ -v` exits 0 with all existing + new TestResume tests passing
</success_criteria>

<output>
After completion, create `.planning/phases/03-resume-fix/03-01-SUMMARY.md` following the summary template.
</output>
